{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                               body\n",
      "0         0  Go until jurong point, crazy.. Available only ...\n",
      "1         0                      Ok lar... Joking wif u oni...\n",
      "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         0  U dun say so early hor... U c already then say...\n",
      "4         0  Nah I don't think he goes to usf, he lives aro...\n",
      "5         1  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6         0  Even my brother is not like to speak with me. ...\n",
      "7         0  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8         1  WINNER!! As a valued network customer you have...\n",
      "9         1  Had your mobile 11 months or more? U R entitle...\n",
      "10        0  I'm gonna be home soon and i don't want to tal...\n",
      "11        1  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12        1  URGENT! You have won a 1 week FREE membership ...\n",
      "13        0  I've been searching for the right words to tha...\n",
      "14        0                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15        1  XXXMobileMovieClub: To use your credit, click ...\n",
      "16        0                         Oh k...i'm watching here:)\n",
      "17        0  Eh u remember how 2 spell his name... Yes i di...\n",
      "18        0  Fine if thats the way u feel. Thats the way ...\n",
      "19        1  England v Macedonia - dont miss the goals/team...\n",
      "20        0          Is that seriously how you spell his name?\n",
      "21        0    I‘m going to try for 2 months ha ha only joking\n",
      "22        0  So ü pay first lar... Then when is da stock co...\n",
      "23        0  Aft i finish my lunch then i go str down lor. ...\n",
      "24        0  Ffffffffff. Alright no way I can meet up with ...\n",
      "25        0  Just forced myself to eat a slice. I'm really ...\n",
      "26        0                     Lol your always so convincing.\n",
      "27        0  Did you catch the bus ? Are you frying an egg ...\n",
      "28        0  I'm back &amp; we're packing the car now, I'll...\n",
      "29        0  Ahhh. Work. I vaguely remember that! What does...\n",
      "...     ...                                                ...\n",
      "5542      0           Armand says get your ass over to epsilon\n",
      "5543      0             U still havent got urself a jacket ah?\n",
      "5544      0  I'm taking derek &amp; taylor to walmart, if I...\n",
      "5545      0      Hi its in durban are you still on this number\n",
      "5546      0         Ic. There are a lotta childporn cars then.\n",
      "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5548      0                 No, I was trying it all weekend ;V\n",
      "5549      0  You know, wot people wear. T shirts, jumpers, ...\n",
      "5550      0        Cool, what time you think you can get here?\n",
      "5551      0  Wen did you get so spiritual and deep. That's ...\n",
      "5552      0  Have a safe trip to Nigeria. Wish you happines...\n",
      "5553      0                        Hahaha..use your brain dear\n",
      "5554      0  Well keep in mind I've only got enough gas for...\n",
      "5555      0  Yeh. Indians was nice. Tho it did kane me off ...\n",
      "5556      0  Yes i have. So that's why u texted. Pshew...mi...\n",
      "5557      0  No. I meant the calculation is the same. That ...\n",
      "5558      0                             Sorry, I'll call later\n",
      "5559      0  if you aren't here in the next  &lt;#&gt;  hou...\n",
      "5560      0                  Anything lor. Juz both of us lor.\n",
      "5561      0  Get me out of this dump heap. My mom decided t...\n",
      "5562      0  Ok lor... Sony ericsson salesman... I ask shuh...\n",
      "5563      0                                Ard 6 like dat lor.\n",
      "5564      0  Why don't you wait 'til at least wednesday to ...\n",
      "5565      0                                       Huh y lei...\n",
      "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567      1  This is the 2nd time we have tried 2 contact u...\n",
      "5568      0               Will ü b going to esplanade fr home?\n",
      "5569      0  Pity, * was in mood for that. So...any other s...\n",
      "5570      0  The guy did some bitching but I acted like i'd...\n",
      "5571      0                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('SMSSpamCollection',  \n",
    "                   sep='\\t', \n",
    "                   header=None,\n",
    "                   names=['label', 'message'])\n",
    "df.columns = ['label','body']\n",
    "# label spam as 1, not spam as 0\n",
    "df['label'] = df['label'].replace([\"ham\",\"spam\"],[0,1])\n",
    "data = df.values\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ngrams_bayes():\n",
    "    \n",
    "    def __init__(self, data, n=2, split=0.75):\n",
    "        \n",
    "        # split into training and testing data\n",
    "        self.train_data, self.test_data = train_test_split(data,\n",
    "                                                          train_size=split)\n",
    "        # convert into n grams\n",
    "        self.train_data = [[item[0], self.ngrams(n, item[1])] for item in self.train_data]\n",
    "        self.test_data = [[item[0], self.ngrams(n, item[1])] for item in self.test_data]\n",
    "        \n",
    "        # count unique n grams in training data\n",
    "        flattened = [gram for message in self.train_data for gram in message[1]]\n",
    "        self.unique = len(set(flattened))\n",
    "        \n",
    "        # init dicts\n",
    "        self.trainPositive = {}\n",
    "        self.trainNegative = {}\n",
    "        # counters\n",
    "        self.posGramCount = 0\n",
    "        self.negGramCount = 0\n",
    "        self.spamCount = 0\n",
    "        # priors\n",
    "        self.pA = 0\n",
    "        self.pNotA = 0\n",
    "        \n",
    "    def ngrams(self, n, text):\n",
    "        text = text.split(' ')\n",
    "        grams = []\n",
    "        for i in range(len(text)-n+1):\n",
    "            gram = ' '.join(text[i:i+n])\n",
    "            grams.append(gram)\n",
    "        return grams \n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        for item in self.train_data:\n",
    "            label = item[0]\n",
    "            grams = item[1]\n",
    "            if label == 1:\n",
    "                self.spamCount += 1   \n",
    "            for gram in grams:\n",
    "                if label == 1:\n",
    "                    self.trainPositive[gram] = self.trainPositive.get(gram, 0) + 1\n",
    "                    self.posGramCount += 1\n",
    "                else:\n",
    "                    self.trainNegative[gram] = self.trainNegative.get(gram, 0) + 1\n",
    "                    self.negGramCount += 1\n",
    "                    \n",
    "        self.pA = self.spamCount/float(len(self.train_data))\n",
    "        self.pNotA = 1.0 - self.pA\n",
    "        \n",
    "    def classify(self, text, alpha=1.0):\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        isSpam = self.pA * self.conditionalText(text, 1)\n",
    "        notSpam = self.pNotA * self.conditionalText(text, 0)\n",
    "        if (isSpam > notSpam):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def conditionalText(self, grams, label):\n",
    "        result = 1.0\n",
    "        for ngram in grams:\n",
    "            result *= self.conditionalNgram(ngram, label)\n",
    "        return result\n",
    "    \n",
    "    def conditionalNgram(self, ngram, label):\n",
    "        alpha = self.alpha\n",
    "        if label == 1:\n",
    "            return ((self.trainPositive.get(ngram,0)+alpha) /\n",
    "                    float(self.posGramCount+alpha*self.unique))\n",
    "        else:\n",
    "            return ((self.trainNegative.get(ngram,0)+alpha) /\n",
    "                    float(self.negGramCount+alpha*self.unique))\n",
    "            \n",
    "    def evaluate_test_data(self):\n",
    "        results = []\n",
    "        for test in self.test_data:\n",
    "            label = test[0]\n",
    "            text = test[1]\n",
    "            ruling = self.classify(text)\n",
    "            if ruling == label:\n",
    "                results.append(1) \n",
    "            else:\n",
    "                results.append(0) \n",
    "                \n",
    "        print(\"Evaluated {} test cases. {:.2f}% Accuracy\".format(len(results), 100.0*sum(results)/float(len(results))))\n",
    "        return sum(results)/float(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jairo Castrellón\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "unigram_bayes = ngrams_bayes(data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_bayes.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 1393 test cases. 96.91% Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9691313711414213"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_bayes.evaluate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jairo Castrellón\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 1393 test cases. 73.44% Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7343862167982771"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_sms= ngrams_bayes(data,2) \n",
    "bigram_sms.train()\n",
    "bigram_sms.evaluate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 1393 test cases. 47.16% Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jairo Castrellón\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47164393395549176"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_sms = ngrams_bayes(data,3) \n",
    "trigram_sms.train()\n",
    "trigram_sms.evaluate_test_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
